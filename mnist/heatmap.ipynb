{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "#import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(123)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "#from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "import itertools\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size: (10015, 10)\n",
      "Shrunk Size: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "base_skin_dir = 'archive/'\n",
    "\n",
    "# Merging images from both folders HAM10000_images_part1.zip and HAM10000_images_part2.zip into one dictionary\n",
    "\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
    "\n",
    "# This dictionary is useful for displaying more human-friendly labels later on\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "skin_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
    "\n",
    "# Creating New Columns for better readability\n",
    "\n",
    "skin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)\n",
    "skin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get) \n",
    "skin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes\n",
    "\n",
    "# skrink dataset\n",
    "print(f\"Original Size: {skin_df.shape}\")\n",
    "skin_df = skin_df.sample(frac=0.01) # shuffle the dataset\n",
    "print(f\"Shrunk Size: {skin_df.shape}\")\n",
    "\n",
    "skin_df['age'].fillna((skin_df['age'].mean()), inplace=True)\n",
    "\n",
    "skin_df['image'] = skin_df['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75))))\n",
    "\n",
    "features=skin_df.drop(columns=['cell_type_idx'],axis=1)\n",
    "target=skin_df['cell_type_idx']\n",
    "\n",
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.20,random_state=1234)\n",
    "\n",
    "x_train = np.asarray(x_train_o['image'].tolist())\n",
    "x_test = np.asarray(x_test_o['image'].tolist())\n",
    "\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean)/x_train_std\n",
    "x_test = (x_test - x_test_mean)/x_test_std\n",
    "\n",
    "# Perform one-hot encoding on the labels\n",
    "y_train = to_categorical(y_train_o, num_classes = 7)\n",
    "y_test = to_categorical(y_test_o, num_classes = 7)\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)\n",
    "x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))\n",
    "\n",
    "input_shape = (75, 100, 3)\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf\u001b[39m.\u001b[39mverion\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 75, 100, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_18'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py:868\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 868\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n\u001b[1;32m    869\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/input_layer.py:153\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[0;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized keyword arguments: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m sparse \u001b[39mand\u001b[39;00m ragged:\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments: ['batch_shape']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39;49m\u001b[39mmodel_4.keras\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/saving/saving_api.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe following argument(s) are not supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith the native Keras format: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[39m=\u001b[39;49msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39mcustom_objects, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/saving/saving_lib.py:275\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    272\u001b[0m             asset_store\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    274\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 275\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/saving/saving_lib.py:240\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 240\u001b[0m     model \u001b[39m=\u001b[39m deserialize_keras_object(\n\u001b[1;32m    241\u001b[0m         config_dict, custom_objects, safe_mode\u001b[39m=\u001b[39;49msafe_mode\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    244\u001b[0m all_filenames \u001b[39m=\u001b[39m zf\u001b[39m.\u001b[39mnamelist()\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m _VARS_FNAME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/saving/serialization_lib.py:704\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m safe_mode_scope \u001b[39m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    703\u001b[0m \u001b[39mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 704\u001b[0m     instance \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(inner_config)\n\u001b[1;32m    705\u001b[0m     build_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbuild_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    706\u001b[0m     \u001b[39mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/sequential.py:471\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mfor\u001b[39;00m layer_config \u001b[39min\u001b[39;00m layer_configs:\n\u001b[1;32m    470\u001b[0m     use_legacy_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodule\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m layer_config\n\u001b[0;32m--> 471\u001b[0m     layer \u001b[39m=\u001b[39m layer_module\u001b[39m.\u001b[39;49mdeserialize(\n\u001b[1;32m    472\u001b[0m         layer_config,\n\u001b[1;32m    473\u001b[0m         custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    474\u001b[0m         use_legacy_format\u001b[39m=\u001b[39;49muse_legacy_format,\n\u001b[1;32m    475\u001b[0m     )\n\u001b[1;32m    476\u001b[0m     model\u001b[39m.\u001b[39madd(layer)\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    479\u001b[0m     \u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39minputs\n\u001b[1;32m    480\u001b[0m     \u001b[39mand\u001b[39;00m build_input_shape\n\u001b[1;32m    481\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(build_input_shape, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))\n\u001b[1;32m    482\u001b[0m ):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/layers/serialization.py:276\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects, use_legacy_format)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m use_legacy_format:\n\u001b[1;32m    269\u001b[0m     \u001b[39mreturn\u001b[39;00m legacy_serialization\u001b[39m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    270\u001b[0m         config,\n\u001b[1;32m    271\u001b[0m         module_objects\u001b[39m=\u001b[39mLOCAL\u001b[39m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m    272\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    273\u001b[0m         printable_module_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlayer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    274\u001b[0m     )\n\u001b[0;32m--> 276\u001b[0m \u001b[39mreturn\u001b[39;00m serialization_lib\u001b[39m.\u001b[39;49mdeserialize_keras_object(\n\u001b[1;32m    277\u001b[0m     config,\n\u001b[1;32m    278\u001b[0m     module_objects\u001b[39m=\u001b[39;49mLOCAL\u001b[39m.\u001b[39;49mALL_OBJECTS,\n\u001b[1;32m    279\u001b[0m     custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    280\u001b[0m     printable_module_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlayer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    281\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/saving/serialization_lib.py:600\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(module_objects[config], types\u001b[39m.\u001b[39mFunctionType):\n\u001b[1;32m    594\u001b[0m             \u001b[39mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[1;32m    595\u001b[0m                 serialize_with_public_fn(\n\u001b[1;32m    596\u001b[0m                     module_objects[config], config, fn_module_name\n\u001b[1;32m    597\u001b[0m                 ),\n\u001b[1;32m    598\u001b[0m                 custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    599\u001b[0m             )\n\u001b[0;32m--> 600\u001b[0m         \u001b[39mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[1;32m    601\u001b[0m             serialize_with_public_class(\n\u001b[1;32m    602\u001b[0m                 module_objects[config], inner_config\u001b[39m=\u001b[39;49minner_config\n\u001b[1;32m    603\u001b[0m             ),\n\u001b[1;32m    604\u001b[0m             custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    605\u001b[0m         )\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PLAIN_TYPES):\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m config\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/saving/serialization_lib.py:704\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m safe_mode_scope \u001b[39m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    703\u001b[0m \u001b[39mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 704\u001b[0m     instance \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(inner_config)\n\u001b[1;32m    705\u001b[0m     build_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbuild_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    706\u001b[0m     \u001b[39mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/base_layer.py:870\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n\u001b[1;32m    869\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 870\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    871\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError when deserializing class \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m using \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig=\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mException encountered: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    873\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 75, 100, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_18'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "model = load_model('model_4.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# Load the model without compiling (set compile=False)\n",
    "#model = load_model('model_test_acc_0.66.keras', compile=False)\n",
    "model = load_model('model_4.keras')\n",
    "\n",
    "# Compile the model with the legacy Adam optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to generate Grad-CAM heatmap\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # Compute the gradient of the top predicted class with respect to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # Pool the gradients over all the axes (average the gradients)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Multiply each channel in the feature map array by \"how important this channel is\" with respect to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # Normalize heatmap between 0 and 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Function to superimpose the heatmap onto the original image\n",
    "def superimpose_heatmap(heatmap, img_array, alpha=0.6):\n",
    "    img = img_array[0]\n",
    "\n",
    "    # Convert heatmap to RGB using the 'hot' colormap to avoid blue tint\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = plt.cm.hot(heatmap)[:, :, :3]  # Apply the 'hot' colormap (no blue)\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = tf.image.resize(np.expand_dims(heatmap, axis=0), (img.shape[0], img.shape[1])).numpy()\n",
    "    heatmap = np.squeeze(heatmap)  # Remove the batch dimension\n",
    "\n",
    "    # Superimpose the heatmap onto the image\n",
    "    superimposed_img = heatmap * alpha + img / 255.0  # Normalize image to [0, 1]\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 1)  # Clip values between 0 and 1\n",
    "    return superimposed_img\n",
    "\n",
    "# Rescale function to undo normalization for proper image display\n",
    "def rescale_image(img, mean, std):\n",
    "    img_rescaled = (img * std) + mean  # Undo normalization\n",
    "    img_rescaled = np.clip(img_rescaled, 0, 255).astype('uint8')  # Ensure pixel values are in range [0, 255]\n",
    "    return img_rescaled\n",
    "\n",
    "# Example: specify a single convolutional layer you want to visualize\n",
    "conv_layer = \"conv2d_16\"  # Replace this with your desired layer\n",
    "\n",
    "# Select an image from the test set\n",
    "img = x_test[9]  # Example: Pick the 11th image from the test set\n",
    "img_rescaled = rescale_image(img, x_test_mean, x_test_std)  # Rescale image\n",
    "\n",
    "# Expand dimensions for Grad-CAM\n",
    "img_expanded = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Generate Grad-CAM heatmap for the specific layer\n",
    "heatmap = make_gradcam_heatmap(img_expanded, model, conv_layer)\n",
    "\n",
    "# Superimpose the heatmap on the rescaled image\n",
    "superimposed_img = superimpose_heatmap(heatmap, np.expand_dims(img_rescaled, axis=0))\n",
    "\n",
    "# Plot the original image and the superimposed heatmap\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Display the original rescaled image\n",
    "'''plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_rescaled)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')'''\n",
    "\n",
    "# Display the heatmap over the rescaled image\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.plot()\n",
    "plt.imshow(superimposed_img)\n",
    "plt.title(f'Heatmap from {conv_layer}')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to generate Grad-CAM heatmap\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # Compute the gradient of the top predicted class with respect to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # Pool the gradients over all the axes (average the gradients)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Multiply each channel in the feature map array by \"how important this channel is\" with respect to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # Normalize heatmap between 0 and 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Function to superimpose the heatmap onto the original image\n",
    "def superimpose_heatmap(heatmap, img_array, alpha=0.6):\n",
    "    img = img_array[0]\n",
    "\n",
    "    # Convert heatmap to RGB using the 'hot' colormap to avoid blue tint\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = plt.cm.hot(heatmap)[:, :, :3]  # Apply the 'hot' colormap (no blue)\n",
    "\n",
    "    # Remove low-activation areas by setting them to 0 (transparent)\n",
    "    heatmap = np.where(heatmap < 0.2, 0, heatmap)  # Threshold for low activations (adjustable)\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = tf.image.resize(np.expand_dims(heatmap, axis=0), (img.shape[0], img.shape[1])).numpy()\n",
    "    heatmap = np.squeeze(heatmap)  # Remove the batch dimension\n",
    "\n",
    "    # Superimpose the heatmap onto the image\n",
    "    superimposed_img = heatmap * alpha + img / 255.0  # Normalize image to [0, 1]\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 1)  # Clip values between 0 and 1\n",
    "    return superimposed_img\n",
    "\n",
    "# Rescale function to undo normalization for proper image display\n",
    "def rescale_image(img, mean, std):\n",
    "    img_rescaled = (img * std) + mean  # Undo normalization\n",
    "    img_rescaled = np.clip(img_rescaled, 0, 255).astype('uint8')  # Ensure pixel values are in range [0, 255]\n",
    "    return img_rescaled\n",
    "\n",
    "# List of convolutional layers to visualize\n",
    "conv_layers = [\"conv2d_36\", \"conv2d_37\", \"conv2d_38\", \"conv2d_39\"]\n",
    "\n",
    "# Select an image from the test set\n",
    "img = x_test[9]  # Example: Pick the 11th image from the test set\n",
    "img_rescaled = rescale_image(img, x_test_mean, x_test_std)  # Rescale image\n",
    "\n",
    "# Expand dimensions for Grad-CAM\n",
    "img_expanded = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Plot original image and heatmaps for each convolutional layer\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Display the original rescaled image in the first subplot\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.imshow(img_rescaled)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Loop through convolutional layers and generate heatmaps\n",
    "for i, conv_layer in enumerate(conv_layers):\n",
    "    # Generate Grad-CAM heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_expanded, model, conv_layer)\n",
    "    \n",
    "    # Superimpose the heatmap on the rescaled image\n",
    "    superimposed_img = superimpose_heatmap(heatmap, np.expand_dims(img_rescaled, axis=0))\n",
    "    \n",
    "    # Display the heatmap over the rescaled image\n",
    "    plt.subplot(3, 2, i + 2)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f'Heatmap from {conv_layer}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Feb  3 2024, 15:58:27) \n[Clang 15.0.0 (clang-1500.3.9.4)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
